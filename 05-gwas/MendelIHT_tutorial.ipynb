{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Iterative hard thresholding Tutorial\n",
    "\n",
    "This notebook showcase a few examples of the software [MendelIHT.jl](https://github.com/OpenMendel/MendelIHT.jl). \n",
    "\n",
    "## Package installation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Julia Version 1.2.0\n",
      "Commit c6da87ff4b (2019-08-20 00:03 UTC)\n",
      "Platform Info:\n",
      "  OS: macOS (x86_64-apple-darwin18.6.0)\n",
      "  CPU: Intel(R) Core(TM) i9-9880H CPU @ 2.30GHz\n",
      "  WORD_SIZE: 64\n",
      "  LIBM: libopenlibm\n",
      "  LLVM: libLLVM-6.0.1 (ORCJIT, skylake)\n"
     ]
    }
   ],
   "source": [
    "# machine information for reproducibility\n",
    "versioninfo()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#load necessary packages, install them if you don't have it\n",
    "using MendelIHT\n",
    "using SnpArrays\n",
    "using DataFrames\n",
    "using Distributions\n",
    "using Random\n",
    "using LinearAlgebra\n",
    "using GLM\n",
    "using DelimitedFiles\n",
    "using Statistics\n",
    "using BenchmarkTools"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To install OpenMendel related packages, execute the following lines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m\u001b[1m  Updating\u001b[22m\u001b[39m registry at `~/.julia/registries/General`\n",
      "\u001b[32m\u001b[1m  Updating\u001b[22m\u001b[39m git-repo `https://github.com/JuliaRegistries/General.git`\n",
      "\u001b[?25l\u001b[2K\u001b[?25h\u001b[32m\u001b[1m  Updating\u001b[22m\u001b[39m git-repo `https://github.com/OpenMendel/SnpArrays.jl`\n",
      "\u001b[?25l\u001b[2K\u001b[?25h\u001b[32m\u001b[1m  Updating\u001b[22m\u001b[39m git-repo `https://github.com/OpenMendel/SnpArrays.jl`\n",
      "\u001b[?25l\u001b[2K\u001b[?25h\u001b[32m\u001b[1m Resolving\u001b[22m\u001b[39m package versions...\n",
      "\u001b[32m\u001b[1m  Updating\u001b[22m\u001b[39m `~/.julia/environments/v1.2/Project.toml`\n",
      "\u001b[90m [no changes]\u001b[39m\n",
      "\u001b[32m\u001b[1m  Updating\u001b[22m\u001b[39m `~/.julia/environments/v1.2/Manifest.toml`\n",
      "\u001b[90m [no changes]\u001b[39m\n"
     ]
    }
   ],
   "source": [
    "]add https://github.com/OpenMendel/SnpArrays.jl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m\u001b[1m  Updating\u001b[22m\u001b[39m git-repo `https://github.com/OpenMendel/MendelSearch.jl`\n",
      "\u001b[?25l\u001b[2K\u001b[?25h\u001b[32m\u001b[1m  Updating\u001b[22m\u001b[39m git-repo `https://github.com/OpenMendel/MendelSearch.jl`\n",
      "\u001b[?25l\u001b[2K\u001b[?25h\u001b[32m\u001b[1m Resolving\u001b[22m\u001b[39m package versions...\n",
      "\u001b[32m\u001b[1m  Updating\u001b[22m\u001b[39m `~/.julia/environments/v1.2/Project.toml`\n",
      "\u001b[90m [no changes]\u001b[39m\n",
      "\u001b[32m\u001b[1m  Updating\u001b[22m\u001b[39m `~/.julia/environments/v1.2/Manifest.toml`\n",
      "\u001b[90m [no changes]\u001b[39m\n"
     ]
    }
   ],
   "source": [
    "]add https://github.com/OpenMendel/MendelSearch.jl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m\u001b[1m  Updating\u001b[22m\u001b[39m git-repo `https://github.com/OpenMendel/MendelBase.jl`\n",
      "\u001b[?25l\u001b[2K\u001b[?25h\u001b[32m\u001b[1m  Updating\u001b[22m\u001b[39m git-repo `https://github.com/OpenMendel/MendelBase.jl`\n",
      "\u001b[?25l\u001b[2K\u001b[?25h\u001b[32m\u001b[1m Resolving\u001b[22m\u001b[39m package versions...\n",
      "\u001b[32m\u001b[1m  Updating\u001b[22m\u001b[39m `~/.julia/environments/v1.2/Project.toml`\n",
      "\u001b[90m [no changes]\u001b[39m\n",
      "\u001b[32m\u001b[1m  Updating\u001b[22m\u001b[39m `~/.julia/environments/v1.2/Manifest.toml`\n",
      "\u001b[90m [no changes]\u001b[39m\n"
     ]
    }
   ],
   "source": [
    "]add https://github.com/OpenMendel/MendelBase.jl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m\u001b[1m  Updating\u001b[22m\u001b[39m git-repo `https://github.com/OpenMendel/MendelIHT.jl`\n",
      "\u001b[?25l\u001b[2K\u001b[?25h\u001b[32m\u001b[1m  Updating\u001b[22m\u001b[39m git-repo `https://github.com/OpenMendel/MendelIHT.jl`\n",
      "\u001b[?25l\u001b[2K\u001b[?25h\u001b[32m\u001b[1m Resolving\u001b[22m\u001b[39m package versions...\n",
      "\u001b[32m\u001b[1m  Updating\u001b[22m\u001b[39m `~/.julia/environments/v1.2/Project.toml`\n",
      "\u001b[90m [no changes]\u001b[39m\n",
      "\u001b[32m\u001b[1m  Updating\u001b[22m\u001b[39m `~/.julia/environments/v1.2/Manifest.toml`\n",
      "\u001b[90m [no changes]\u001b[39m\n"
     ]
    }
   ],
   "source": [
    "]add https://github.com/OpenMendel/MendelIHT.jl"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# What is IHT?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Iterative hard thresholding (IHT) is a sparse approximation method that performs variable selection and parameter estimation for high dimensional datasets. IHT returns a sparse model with prespecified $k \\in \\mathbb{Z}_+$ (or fewer) non-zero entries. In [MendelIHT.j](), the objective function is:\n",
    "\n",
    "\\begin{align}\n",
    "\\text{maximize } & \\quad L(\\beta)\\\\\n",
    "\\text{subject to } & \\quad ||\\beta||_0 \\le k\n",
    "\\end{align}\n",
    "\n",
    "The objective is solved via:\n",
    "$$\\beta_{n+1} = P_{S_k}(\\beta_n - s_n \\nabla L(\\beta_n)),$$\n",
    "where:\n",
    "+ $\\nabla L(\\beta)$ is the score (gradient) vector of loglikelihood\n",
    "+ $J(\\beta)$ is the expected information (hessian) matrix\n",
    "+ $s = \\frac{||\\nabla L(\\beta)||_2^2}{\\nabla L(\\beta)^tJ(\\beta)\\nabla L(\\beta)}$ is the step size\n",
    "+ $P_{S_k}(v)$ projects vector $v$ to sparsity set $S_k$ by setting all but the top $k$ entries to 0. \n",
    "\n",
    "See [our paper](https://www.biorxiv.org/content/10.1101/697755v2) for more details and computational tricks to do each of these efficiently."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Supported GLM models and Link functions\n",
    "\n",
    "MendelIHT borrows distribution and link functions implementationed in [GLM.jl](http://juliastats.github.io/GLM.jl/stable/) and [Distributions.jl](https://juliastats.github.io/Distributions.jl/stable/).\n",
    "\n",
    "| Distribution | Canonical Link | Status |\n",
    "|:---:|:---:|:---:|\n",
    "| Normal | IdentityLink | $\\checkmark$ |\n",
    "| Bernoulli | LogitLink |$\\checkmark$ |\n",
    "| Poisson | LogLink |  $\\checkmark$ |\n",
    "| NegativeBinomial | LogLink |  $\\checkmark$ |\n",
    "| Gamma | InverseLink | experimental |\n",
    "| InverseGaussian | InverseSquareLink | experimental |\n",
    "\n",
    "Examples of these distributions in their default value is visualized in [this post](https://github.com/JuliaStats/GLM.jl/issues/289).\n",
    "\n",
    "### Available link functions\n",
    "\n",
    "    CauchitLink\n",
    "    CloglogLink\n",
    "    IdentityLink\n",
    "    InverseLink\n",
    "    InverseSquareLink\n",
    "    LogitLink\n",
    "    LogLink\n",
    "    ProbitLink\n",
    "    SqrtLink"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Example 1: How to Import Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Simulate example data (to be imported later)\n",
    "\n",
    "First we simulate an example PLINK trio (`.bim`, `.bed`, `.fam`) and non-genetic covariates, then we illustrate how to import them. For genotype matrix simulation, we simulate under the model:\n",
    "\n",
    "$$x_{ij} \\sim \\rm Binomial(2, \\rho_j)$$\n",
    "$$\\rho_j \\sim \\rm Uniform(0, 0.5)$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# rows and columns\n",
    "n = 1000\n",
    "p = 10000\n",
    "\n",
    "#random seed\n",
    "Random.seed!(2020)\n",
    "\n",
    "# simulate random `.bed` file\n",
    "x = simulate_random_snparray(n, p, \"./data/tmp.bed\")\n",
    "\n",
    "# create accompanying `.bim`, `.fam` files (randomly generated)\n",
    "make_bim_fam_files(x, ones(n), \"./data/tmp\")\n",
    "\n",
    "# simulate non-genetic covariates (in this case, we include intercept and sex)\n",
    "z = [ones(n, 1) rand(0:1, n)]\n",
    "writedlm(\"./data/tmp_nongenetic_covariates.txt\", z)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reading Genotype data and Non-Genetic Covariates from disk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1000×2 Array{Float64,2}:\n",
       " 1.0  0.0\n",
       " 1.0  0.0\n",
       " 1.0  0.0\n",
       " 1.0  0.0\n",
       " 1.0  1.0\n",
       " 1.0  1.0\n",
       " 1.0  0.0\n",
       " 1.0  1.0\n",
       " 1.0  1.0\n",
       " 1.0  0.0\n",
       " 1.0  1.0\n",
       " 1.0  1.0\n",
       " 1.0  0.0\n",
       " ⋮       \n",
       " 1.0  1.0\n",
       " 1.0  0.0\n",
       " 1.0  1.0\n",
       " 1.0  1.0\n",
       " 1.0  0.0\n",
       " 1.0  0.0\n",
       " 1.0  1.0\n",
       " 1.0  1.0\n",
       " 1.0  0.0\n",
       " 1.0  0.0\n",
       " 1.0  1.0\n",
       " 1.0  0.0"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = SnpArray(\"./data/tmp.bed\")\n",
    "z = readdlm(\"./data/tmp_nongenetic_covariates.txt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Standardizing Non-Genetic Covariates.\n",
    "\n",
    "We recommend standardizing all genetic and non-genetic covarariates (including binary and categorical), except for the intercept. This ensures equal penalization for all predictors. For genotype matrix, `SnpBitMatrix` efficiently achieves this standardization. For non-genetic covariates, we use the built-in function `standardize!`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1000×2 Array{Float64,2}:\n",
       " 1.0  -0.952622\n",
       " 1.0  -0.952622\n",
       " 1.0  -0.952622\n",
       " 1.0  -0.952622\n",
       " 1.0   1.04868 \n",
       " 1.0   1.04868 \n",
       " 1.0  -0.952622\n",
       " 1.0   1.04868 \n",
       " 1.0   1.04868 \n",
       " 1.0  -0.952622\n",
       " 1.0   1.04868 \n",
       " 1.0   1.04868 \n",
       " 1.0  -0.952622\n",
       " ⋮             \n",
       " 1.0   1.04868 \n",
       " 1.0  -0.952622\n",
       " 1.0   1.04868 \n",
       " 1.0   1.04868 \n",
       " 1.0  -0.952622\n",
       " 1.0  -0.952622\n",
       " 1.0   1.04868 \n",
       " 1.0   1.04868 \n",
       " 1.0  -0.952622\n",
       " 1.0  -0.952622\n",
       " 1.0   1.04868 \n",
       " 1.0  -0.952622"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# SnpBitMatrix can automatically standardizes .bed file (without extra memory) and behaves like a matrix\n",
    "xbm = SnpBitMatrix{Float64}(x, model=ADDITIVE_MODEL, center=true, scale=true);\n",
    "\n",
    "# using view is important for correctness\n",
    "standardize!(@view(z[:, 2:end])) \n",
    "z"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Example 2: Running IHT on Quantitative Traits"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this example, our model is simulated as:\n",
    "\n",
    "$$y_i \\sim \\mathbf{x}_i^T\\mathbf{\\beta} + \\epsilon_i$$\n",
    "$$x_{ij} \\sim \\rm Binomial(2, \\rho_j)$$\n",
    "$$\\rho_j \\sim \\rm Uniform(0, 0.5)$$\n",
    "$$\\epsilon_i \\sim \\rm N(0, 1)$$\n",
    "$$\\beta_i \\sim \\rm N(0, 1)$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Define model dimensions, true model size, distribution, and link functions\n",
    "n = 1000\n",
    "p = 10000\n",
    "k = 10\n",
    "d = Normal\n",
    "l = canonicallink(d())\n",
    "\n",
    "# set random seed for reproducibility\n",
    "Random.seed!(2020)\n",
    "\n",
    "# simulate SNP matrix, store the result in a file called tmp.bed\n",
    "x = simulate_random_snparray(n, p, \"./data/tmp.bed\")\n",
    "\n",
    "#construct the SnpBitMatrix type (needed for L0_reg() and simulate_random_response() below)\n",
    "xbm = SnpBitMatrix{Float64}(x, model=ADDITIVE_MODEL, center=true, scale=true); \n",
    "\n",
    "# intercept is the only nongenetic covariate\n",
    "z = ones(n, 1) \n",
    "\n",
    "# simulate response y, true model b, and the correct non-0 positions of b\n",
    "y, true_b, correct_position = simulate_random_response(x, xbm, k, d, l);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: Run `q`-fold cross validation to determine best model size\n",
    "\n",
    "To run `cv_iht`, you must specify `path` and `q`, defined below:\n",
    "\n",
    "+ **`path`**: all the model sizes you wish to test.\n",
    "+ **`q`**: number of disjoint partitions of your data. \n",
    "\n",
    "By default, we partition the training/testing data randomly, but you can change this by inputing the `fold` vector as optional argument. In this example we tested $k = 5, 6, ..., 15$ across 3 fold cross validation. This is equivalent to running IHT across 30 different models, and hence, is ideal for parallel computing (which you specify by `parallel=true`). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Crossvalidation Results:\n",
      "\tk\tMSE\n",
      "\t5\t372.3937119552455\n",
      "\t6\t353.5092453930539\n",
      "\t7\t336.18623388015544\n",
      "\t8\t342.3436390290969\n",
      "\t9\t355.6163808836806\n",
      "\t10\t355.92769511323513\n",
      "\t11\t367.05441286229495\n",
      "\t12\t374.1270669623582\n",
      "\t13\t368.0104754338581\n",
      "\t14\t367.4956307418699\n",
      "\t15\t385.3773400406478\n",
      " 15.336045 seconds (15.66 M allocations: 847.403 MiB, 2.54% gc time)\n"
     ]
    }
   ],
   "source": [
    "path = collect(5:15)\n",
    "q = 3\n",
    "\n",
    "@time mses = cv_iht(d(), l, x, z, y, 1, path, q, parallel=false); # don't run parallel on binder!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: Run IHT on full model for best estimated k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\n",
       "IHT estimated 7 nonzero SNP predictors and 0 non-genetic predictors.\n",
       "\n",
       "Compute time (sec):     0.26702284812927246\n",
       "Final loglikelihood:    -1409.8966823858416\n",
       "Iterations:             5\n",
       "\n",
       "Selected genetic predictors:\n",
       "7×2 DataFrame\n",
       "│ Row │ Position │ Estimated_β │\n",
       "│     │ \u001b[90mInt64\u001b[39m    │ \u001b[90mFloat64\u001b[39m     │\n",
       "├─────┼──────────┼─────────────┤\n",
       "│ 1   │ 173      │ 0.240557    │\n",
       "│ 2   │ 4779     │ -1.10532    │\n",
       "│ 3   │ 7159     │ 1.19246     │\n",
       "│ 4   │ 7357     │ 1.63064     │\n",
       "│ 5   │ 8276     │ 0.222044    │\n",
       "│ 6   │ 8529     │ -0.4526     │\n",
       "│ 7   │ 8942     │ -0.890789   │\n",
       "\n",
       "Selected nongenetic predictors:\n",
       "0×2 DataFrame\n"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_k = path[argmin(mses)]\n",
    "result = L0_reg(x, xbm, z, y, 1, best_k, d(), l) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check final model against simulation\n",
    "\n",
    "Since all our data and model was simulated, we can see how well `cv_iht` combined with `L0_reg` estimated the true model. For this example, we find that IHT found every simulated predictor, with 0 false positives. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"data-frame\"><thead><tr><th></th><th>true_β</th><th>estimated_β</th></tr><tr><th></th><th>Float64</th><th>Float64</th></tr></thead><tbody><p>10 rows × 2 columns</p><tr><th>1</th><td>0.290051</td><td>0.240557</td></tr><tr><th>2</th><td>0.113896</td><td>0.0</td></tr><tr><th>3</th><td>-1.09083</td><td>-1.10532</td></tr><tr><th>4</th><td>0.0326341</td><td>0.0</td></tr><tr><th>5</th><td>1.25615</td><td>1.19246</td></tr><tr><th>6</th><td>1.5655</td><td>1.63064</td></tr><tr><th>7</th><td>-0.0616128</td><td>0.0</td></tr><tr><th>8</th><td>0.240515</td><td>0.222044</td></tr><tr><th>9</th><td>-0.420895</td><td>-0.4526</td></tr><tr><th>10</th><td>-0.893621</td><td>-0.890789</td></tr></tbody></table>"
      ],
      "text/latex": [
       "\\begin{tabular}{r|cc}\n",
       "\t& true\\_β & estimated\\_β\\\\\n",
       "\t\\hline\n",
       "\t& Float64 & Float64\\\\\n",
       "\t\\hline\n",
       "\t1 & 0.290051 & 0.240557 \\\\\n",
       "\t2 & 0.113896 & 0.0 \\\\\n",
       "\t3 & -1.09083 & -1.10532 \\\\\n",
       "\t4 & 0.0326341 & 0.0 \\\\\n",
       "\t5 & 1.25615 & 1.19246 \\\\\n",
       "\t6 & 1.5655 & 1.63064 \\\\\n",
       "\t7 & -0.0616128 & 0.0 \\\\\n",
       "\t8 & 0.240515 & 0.222044 \\\\\n",
       "\t9 & -0.420895 & -0.4526 \\\\\n",
       "\t10 & -0.893621 & -0.890789 \\\\\n",
       "\\end{tabular}\n"
      ],
      "text/plain": [
       "10×2 DataFrame\n",
       "│ Row │ true_β     │ estimated_β │\n",
       "│     │ \u001b[90mFloat64\u001b[39m    │ \u001b[90mFloat64\u001b[39m     │\n",
       "├─────┼────────────┼─────────────┤\n",
       "│ 1   │ 0.290051   │ 0.240557    │\n",
       "│ 2   │ 0.113896   │ 0.0         │\n",
       "│ 3   │ -1.09083   │ -1.10532    │\n",
       "│ 4   │ 0.0326341  │ 0.0         │\n",
       "│ 5   │ 1.25615    │ 1.19246     │\n",
       "│ 6   │ 1.5655     │ 1.63064     │\n",
       "│ 7   │ -0.0616128 │ 0.0         │\n",
       "│ 8   │ 0.240515   │ 0.222044    │\n",
       "│ 9   │ -0.420895  │ -0.4526     │\n",
       "│ 10  │ -0.893621  │ -0.890789   │"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "compare_model = DataFrame(\n",
    "    true_β      = true_b[correct_position], \n",
    "    estimated_β = result.beta[correct_position])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Conclusion:** IHT found 7/10 true predictors, with superb parameter estimates. The remaining 3 predictors cannot be identified by IHT because they have very small effect sizes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Example 3: Negative Binomial regression with group information \n",
    "\n",
    "Now we show how to include group information to perform **doubly sparse** projections. This results in a model with at most $j$ groups where each group contains at most $k$ SNPs. This is useful for:\n",
    "\n",
    "+ Data with extensive LD blocks (i.e. correlated covariates)\n",
    "+ Prior knowledge on genes/pathways\n",
    "\n",
    "## Simulation: IHT on extensive LD blocks\n",
    "In this example, we simulated:\n",
    "+ 10,000 SNPs, each belonging to 1 of 500 disjoint groups. Each group contains 20 SNPs\n",
    "+ $j = 5$ distinct groups are each assigned $1,2,...,5$ causal SNPs with effect sizes randomly chosen from $\\{−0.2,0.2\\}$. \n",
    "+ Within group correlation: $\\rho = 0.95$\n",
    "\n",
    "**We assume perfect group information**. That is, the selected groups containing 1∼5 causative SNPs are assigned maximum within-group sparsity $\\lambda_g = 1,2,...,5$. The remaining groups are assigned $\\lambda_g = 1$ (i.e. only 1 active predictor are allowed)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# define problem size\n",
    "d = NegativeBinomial\n",
    "l = LogLink()\n",
    "n = 1000\n",
    "p = 10000\n",
    "block_size = 20                  #simulation parameter\n",
    "num_blocks = Int(p / block_size) #simulation parameter\n",
    "\n",
    "# set seed\n",
    "Random.seed!(2020)\n",
    "\n",
    "# assign group membership\n",
    "membership = collect(1:num_blocks)\n",
    "g = zeros(Int64, p + 1)\n",
    "for i in 1:length(membership)\n",
    "    for j in 1:block_size\n",
    "        cur_row = block_size * (i - 1) + j\n",
    "        g[block_size*(i - 1) + j] = membership[i]\n",
    "    end\n",
    "end\n",
    "g[end] = membership[end]\n",
    "\n",
    "#simulate correlated snparray\n",
    "x = simulate_correlated_snparray(n, p, \"./data/tmp2.bed\", prob=0.95)\n",
    "z = ones(n, 1) # the intercept\n",
    "x_float = convert(Matrix{Float64}, x, model=ADDITIVE_MODEL, center=true, scale=true)\n",
    "\n",
    "#simulate true model, where 5 groups each with 1~5 snps contribute\n",
    "true_b = zeros(p)\n",
    "true_groups = randperm(num_blocks)[1:5]\n",
    "sort!(true_groups)\n",
    "within_group = [randperm(block_size)[1:1], randperm(block_size)[1:2], \n",
    "                randperm(block_size)[1:3], randperm(block_size)[1:4], \n",
    "                randperm(block_size)[1:5]]\n",
    "correct_position = zeros(Int64, 15)\n",
    "for i in 1:5\n",
    "    cur_group = block_size * (true_groups[i] - 1)\n",
    "    cur_group_snps = cur_group .+ within_group[i]\n",
    "    start, last = Int(i*(i-1)/2 + 1), Int(i*(i+1)/2)\n",
    "    correct_position[start:last] .= cur_group_snps\n",
    "end\n",
    "for i in 1:15\n",
    "    true_b[correct_position[i]] = rand(-1:2:1) * 0.2\n",
    "end\n",
    "sort!(correct_position)\n",
    "\n",
    "# simulate phenotype\n",
    "r = 10 #nuisance parameter\n",
    "μ = GLM.linkinv.(l, x_float * true_b)\n",
    "clamp!(μ, -20, 20)\n",
    "prob = 1 ./ (1 .+ μ ./ r)\n",
    "y = [rand(d(r, i)) for i in prob] #number of failures before r success occurs\n",
    "y = Float64.(y);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## IHT without group information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\n",
       "IHT estimated 15 nonzero SNP predictors and 0 non-genetic predictors.\n",
       "\n",
       "Compute time (sec):     0.27208900451660156\n",
       "Final loglikelihood:    -1506.9803043373497\n",
       "Iterations:             56\n",
       "\n",
       "Selected genetic predictors:\n",
       "15×2 DataFrame\n",
       "│ Row │ Position │ Estimated_β │\n",
       "│     │ \u001b[90mInt64\u001b[39m    │ \u001b[90mFloat64\u001b[39m     │\n",
       "├─────┼──────────┼─────────────┤\n",
       "│ 1   │ 4476     │ -0.12189    │\n",
       "│ 2   │ 4477     │ -0.12189    │\n",
       "│ 3   │ 4509     │ -0.173135   │\n",
       "│ 4   │ 4516     │ -0.159284   │\n",
       "│ 5   │ 5382     │ -0.173063   │\n",
       "│ 6   │ 5384     │ -0.0968715  │\n",
       "│ 7   │ 5385     │ -0.0968715  │\n",
       "│ 8   │ 5386     │ -0.0968715  │\n",
       "│ 9   │ 7442     │ 0.194584    │\n",
       "│ 10  │ 7443     │ 0.194584    │\n",
       "│ 11  │ 7446     │ 0.337898    │\n",
       "│ 12  │ 8531     │ 0.195654    │\n",
       "│ 13  │ 8532     │ 0.195654    │\n",
       "│ 14  │ 8535     │ 0.161302    │\n",
       "│ 15  │ 8536     │ 0.151602    │\n",
       "\n",
       "Selected nongenetic predictors:\n",
       "0×2 DataFrame\n"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "k = 15\n",
    "ungrouped_IHT = L0_reg(x_float, z, y, 1, k, d(), l) # 1 means 1 active group = entire dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## IHT with group information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\n",
       "IHT estimated 15 nonzero SNP predictors and 0 non-genetic predictors.\n",
       "\n",
       "Compute time (sec):     0.3959381580352783\n",
       "Final loglikelihood:    -1490.9710283926524\n",
       "Iterations:             48\n",
       "\n",
       "Selected genetic predictors:\n",
       "15×2 DataFrame\n",
       "│ Row │ Position │ Estimated_β │\n",
       "│     │ \u001b[90mInt64\u001b[39m    │ \u001b[90mFloat64\u001b[39m     │\n",
       "├─────┼──────────┼─────────────┤\n",
       "│ 1   │ 4475     │ -0.210736   │\n",
       "│ 2   │ 4509     │ -0.173963   │\n",
       "│ 3   │ 4517     │ -0.155094   │\n",
       "│ 4   │ 5381     │ -0.16722    │\n",
       "│ 5   │ 5382     │ -0.16722    │\n",
       "│ 6   │ 5397     │ 0.267128    │\n",
       "│ 7   │ 7442     │ 0.176729    │\n",
       "│ 8   │ 7443     │ 0.176729    │\n",
       "│ 9   │ 7446     │ 0.288789    │\n",
       "│ 10  │ 7450     │ 0.139096    │\n",
       "│ 11  │ 8526     │ -0.196314   │\n",
       "│ 12  │ 8531     │ 0.48662     │\n",
       "│ 13  │ 8534     │ 0.0427654   │\n",
       "│ 14  │ 8536     │ 0.233248    │\n",
       "│ 15  │ 8540     │ 0.0302228   │\n",
       "\n",
       "Selected nongenetic predictors:\n",
       "0×2 DataFrame\n"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# specify maximum number of active groups\n",
    "J = 5 \n",
    "\n",
    "# specify within-group sparsity for each group\n",
    "max_group_snps = ones(Int, num_blocks) \n",
    "max_group_snps[true_groups] .= collect(1:5)\n",
    "\n",
    "# run grouped IHT\n",
    "grouped_IHT = L0_reg(x_float, z, y, J, max_group_snps, d(), l, verbose=false, group=g)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check variable selection against true data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"data-frame\"><thead><tr><th></th><th>correct_positions</th><th>ungrouped_IHT_positions</th><th>grouped_IHT_positions</th></tr><tr><th></th><th>Int64</th><th>Int64</th><th>Int64</th></tr></thead><tbody><p>15 rows × 3 columns</p><tr><th>1</th><td>4477</td><td>4476</td><td>4475</td></tr><tr><th>2</th><td>4510</td><td>4477</td><td>4509</td></tr><tr><th>3</th><td>4517</td><td>4509</td><td>4517</td></tr><tr><th>4</th><td>5381</td><td>4516</td><td>5381</td></tr><tr><th>5</th><td>5385</td><td>5382</td><td>5382</td></tr><tr><th>6</th><td>5397</td><td>5384</td><td>5397</td></tr><tr><th>7</th><td>7443</td><td>5385</td><td>7442</td></tr><tr><th>8</th><td>7444</td><td>5386</td><td>7443</td></tr><tr><th>9</th><td>7446</td><td>7442</td><td>7446</td></tr><tr><th>10</th><td>7452</td><td>7443</td><td>7450</td></tr><tr><th>11</th><td>8526</td><td>7446</td><td>8526</td></tr><tr><th>12</th><td>8531</td><td>8531</td><td>8531</td></tr><tr><th>13</th><td>8532</td><td>8532</td><td>8534</td></tr><tr><th>14</th><td>8534</td><td>8535</td><td>8536</td></tr><tr><th>15</th><td>8536</td><td>8536</td><td>8540</td></tr></tbody></table>"
      ],
      "text/latex": [
       "\\begin{tabular}{r|ccc}\n",
       "\t& correct\\_positions & ungrouped\\_IHT\\_positions & grouped\\_IHT\\_positions\\\\\n",
       "\t\\hline\n",
       "\t& Int64 & Int64 & Int64\\\\\n",
       "\t\\hline\n",
       "\t1 & 4477 & 4476 & 4475 \\\\\n",
       "\t2 & 4510 & 4477 & 4509 \\\\\n",
       "\t3 & 4517 & 4509 & 4517 \\\\\n",
       "\t4 & 5381 & 4516 & 5381 \\\\\n",
       "\t5 & 5385 & 5382 & 5382 \\\\\n",
       "\t6 & 5397 & 5384 & 5397 \\\\\n",
       "\t7 & 7443 & 5385 & 7442 \\\\\n",
       "\t8 & 7444 & 5386 & 7443 \\\\\n",
       "\t9 & 7446 & 7442 & 7446 \\\\\n",
       "\t10 & 7452 & 7443 & 7450 \\\\\n",
       "\t11 & 8526 & 7446 & 8526 \\\\\n",
       "\t12 & 8531 & 8531 & 8531 \\\\\n",
       "\t13 & 8532 & 8532 & 8534 \\\\\n",
       "\t14 & 8534 & 8535 & 8536 \\\\\n",
       "\t15 & 8536 & 8536 & 8540 \\\\\n",
       "\\end{tabular}\n"
      ],
      "text/plain": [
       "15×3 DataFrame\n",
       "│ Row │ correct_positions │ ungrouped_IHT_positions │ grouped_IHT_positions │\n",
       "│     │ \u001b[90mInt64\u001b[39m             │ \u001b[90mInt64\u001b[39m                   │ \u001b[90mInt64\u001b[39m                 │\n",
       "├─────┼───────────────────┼─────────────────────────┼───────────────────────┤\n",
       "│ 1   │ 4477              │ 4476                    │ 4475                  │\n",
       "│ 2   │ 4510              │ 4477                    │ 4509                  │\n",
       "│ 3   │ 4517              │ 4509                    │ 4517                  │\n",
       "│ 4   │ 5381              │ 4516                    │ 5381                  │\n",
       "│ 5   │ 5385              │ 5382                    │ 5382                  │\n",
       "│ 6   │ 5397              │ 5384                    │ 5397                  │\n",
       "│ 7   │ 7443              │ 5385                    │ 7442                  │\n",
       "│ 8   │ 7444              │ 5386                    │ 7443                  │\n",
       "│ 9   │ 7446              │ 7442                    │ 7446                  │\n",
       "│ 10  │ 7452              │ 7443                    │ 7450                  │\n",
       "│ 11  │ 8526              │ 7446                    │ 8526                  │\n",
       "│ 12  │ 8531              │ 8531                    │ 8531                  │\n",
       "│ 13  │ 8532              │ 8532                    │ 8534                  │\n",
       "│ 14  │ 8534              │ 8535                    │ 8536                  │\n",
       "│ 15  │ 8536              │ 8536                    │ 8540                  │"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "compare_model = DataFrame(\n",
    "    correct_positions = correct_position,\n",
    "    ungrouped_IHT_positions = findall(!iszero, ungrouped_IHT.beta),\n",
    "    grouped_IHT_positions = findall(!iszero, grouped_IHT.beta))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check estimated parameters against true data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"data-frame\"><thead><tr><th></th><th>position</th><th>correct_β</th><th>ungrouped_IHT_β</th><th>grouped_IHT_β</th></tr><tr><th></th><th>Int64</th><th>Float64</th><th>Float64</th><th>Float64</th></tr></thead><tbody><p>15 rows × 4 columns</p><tr><th>1</th><td>4477</td><td>-0.2</td><td>-0.12189</td><td>0.0</td></tr><tr><th>2</th><td>4510</td><td>-0.2</td><td>0.0</td><td>0.0</td></tr><tr><th>3</th><td>4517</td><td>-0.2</td><td>0.0</td><td>-0.155094</td></tr><tr><th>4</th><td>5381</td><td>-0.2</td><td>0.0</td><td>-0.16722</td></tr><tr><th>5</th><td>5385</td><td>-0.2</td><td>-0.0968715</td><td>0.0</td></tr><tr><th>6</th><td>5397</td><td>0.2</td><td>0.0</td><td>0.267128</td></tr><tr><th>7</th><td>7443</td><td>0.2</td><td>0.194584</td><td>0.176729</td></tr><tr><th>8</th><td>7444</td><td>0.2</td><td>0.0</td><td>0.0</td></tr><tr><th>9</th><td>7446</td><td>0.2</td><td>0.337898</td><td>0.288789</td></tr><tr><th>10</th><td>7452</td><td>0.2</td><td>0.0</td><td>0.0</td></tr><tr><th>11</th><td>8526</td><td>-0.2</td><td>0.0</td><td>-0.196314</td></tr><tr><th>12</th><td>8531</td><td>0.2</td><td>0.195654</td><td>0.48662</td></tr><tr><th>13</th><td>8532</td><td>0.2</td><td>0.195654</td><td>0.0</td></tr><tr><th>14</th><td>8534</td><td>0.2</td><td>0.0</td><td>0.0427654</td></tr><tr><th>15</th><td>8536</td><td>0.2</td><td>0.151602</td><td>0.233248</td></tr></tbody></table>"
      ],
      "text/latex": [
       "\\begin{tabular}{r|cccc}\n",
       "\t& position & correct\\_β & ungrouped\\_IHT\\_β & grouped\\_IHT\\_β\\\\\n",
       "\t\\hline\n",
       "\t& Int64 & Float64 & Float64 & Float64\\\\\n",
       "\t\\hline\n",
       "\t1 & 4477 & -0.2 & -0.12189 & 0.0 \\\\\n",
       "\t2 & 4510 & -0.2 & 0.0 & 0.0 \\\\\n",
       "\t3 & 4517 & -0.2 & 0.0 & -0.155094 \\\\\n",
       "\t4 & 5381 & -0.2 & 0.0 & -0.16722 \\\\\n",
       "\t5 & 5385 & -0.2 & -0.0968715 & 0.0 \\\\\n",
       "\t6 & 5397 & 0.2 & 0.0 & 0.267128 \\\\\n",
       "\t7 & 7443 & 0.2 & 0.194584 & 0.176729 \\\\\n",
       "\t8 & 7444 & 0.2 & 0.0 & 0.0 \\\\\n",
       "\t9 & 7446 & 0.2 & 0.337898 & 0.288789 \\\\\n",
       "\t10 & 7452 & 0.2 & 0.0 & 0.0 \\\\\n",
       "\t11 & 8526 & -0.2 & 0.0 & -0.196314 \\\\\n",
       "\t12 & 8531 & 0.2 & 0.195654 & 0.48662 \\\\\n",
       "\t13 & 8532 & 0.2 & 0.195654 & 0.0 \\\\\n",
       "\t14 & 8534 & 0.2 & 0.0 & 0.0427654 \\\\\n",
       "\t15 & 8536 & 0.2 & 0.151602 & 0.233248 \\\\\n",
       "\\end{tabular}\n"
      ],
      "text/plain": [
       "15×4 DataFrame\n",
       "│ Row │ position │ correct_β │ ungrouped_IHT_β │ grouped_IHT_β │\n",
       "│     │ \u001b[90mInt64\u001b[39m    │ \u001b[90mFloat64\u001b[39m   │ \u001b[90mFloat64\u001b[39m         │ \u001b[90mFloat64\u001b[39m       │\n",
       "├─────┼──────────┼───────────┼─────────────────┼───────────────┤\n",
       "│ 1   │ 4477     │ -0.2      │ -0.12189        │ 0.0           │\n",
       "│ 2   │ 4510     │ -0.2      │ 0.0             │ 0.0           │\n",
       "│ 3   │ 4517     │ -0.2      │ 0.0             │ -0.155094     │\n",
       "│ 4   │ 5381     │ -0.2      │ 0.0             │ -0.16722      │\n",
       "│ 5   │ 5385     │ -0.2      │ -0.0968715      │ 0.0           │\n",
       "│ 6   │ 5397     │ 0.2       │ 0.0             │ 0.267128      │\n",
       "│ 7   │ 7443     │ 0.2       │ 0.194584        │ 0.176729      │\n",
       "│ 8   │ 7444     │ 0.2       │ 0.0             │ 0.0           │\n",
       "│ 9   │ 7446     │ 0.2       │ 0.337898        │ 0.288789      │\n",
       "│ 10  │ 7452     │ 0.2       │ 0.0             │ 0.0           │\n",
       "│ 11  │ 8526     │ -0.2      │ 0.0             │ -0.196314     │\n",
       "│ 12  │ 8531     │ 0.2       │ 0.195654        │ 0.48662       │\n",
       "│ 13  │ 8532     │ 0.2       │ 0.195654        │ 0.0           │\n",
       "│ 14  │ 8534     │ 0.2       │ 0.0             │ 0.0427654     │\n",
       "│ 15  │ 8536     │ 0.2       │ 0.151602        │ 0.233248      │"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#check result\n",
    "correct_position = findall(!iszero, true_b)\n",
    "compare_model = DataFrame(\n",
    "    position = correct_position,\n",
    "    correct_β = true_b[correct_position],\n",
    "    ungrouped_IHT_β = ungrouped_IHT.beta[correct_position], \n",
    "    grouped_IHT_β = grouped_IHT.beta[correct_position])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Conclusion:** by asking for \"top entries\" in each group, we (somewhat) disentangle the correlation structure in our data and achieved better model selection!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## More examples:\n",
    "\n",
    "Please visit our [documentation](https://openmendel.github.io/MendelIHT.jl/latest/).\n",
    "\n",
    "## Other functionalities\n",
    "\n",
    "+ Analyze large GWAS datasets intuitively.\n",
    "+ Built-in support for [PLINK binary files](https://www.cog-genomics.org/plink/1.9/input#bed) via [SnpArrays.jl](https://github.com/OpenMendel/SnpArrays.jl) and [VCF files](https://en.wikipedia.org/wiki/Variant_Call_Format) via [VCFTools.jl](https://github.com/OpenMendel/VCFTools.jl).\n",
    "+ Out-of-the-box parallel computing routines for `q-fold` cross-validation.\n",
    "+ Fits a variety of generalized linear models with any choice of link function.\n",
    "+ Computation directly on raw genotype files.\n",
    "+ Efficient handlings for non-genetic covariates.\n",
    "+ Optional acceleration (debias) step to dramatically improve speed.\n",
    "+ Ability to explicitly incorporate weights for predictors.\n",
    "+ Ability to enforce within and between group sparsity. \n",
    "+ Naive genotype imputation. \n",
    "+ Estimates nuisance parameter for negative binomial regression using Newton or MM algorithm. \n",
    "+ Excellent flexibility to handle different data structures and complements well with other Julia packages."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.2.0",
   "language": "julia",
   "name": "julia-1.2"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.2.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
